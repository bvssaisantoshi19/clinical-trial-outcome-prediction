{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce7ec2c-4e5e-477e-83f8-459e813f7bd6",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook: `1_df_studies.ipynb`\n",
    "\n",
    "### Description\n",
    "Processes the `studies` table from the AACT Clinical Trials database to create a cleaned and feature-engineered dataset ready for downstream analysis and modeling.  \n",
    "This is the **first notebook** in the data preprocessing pipeline.\n",
    "\n",
    "### Key Steps\n",
    "- Load selected columns from the `studies` table via SQLAlchemy.  \n",
    "- Filter only *interventional* studies.  \n",
    "- Generate binary outcome variable (`overall_status` â†’ success/failure).  \n",
    "- Handle missing values and convert column datatypes.  \n",
    "- Parse start and completion dates to calculate **study duration**.  \n",
    "- Clean and standardize the `phase` column.  \n",
    "- Impute missing `enrollment` values and **reassign mixed phases (Phase 1/2, Phase 2/3)** based on median enrollment size.  \n",
    "- One-hot encode `phase` and encode flag like columns \n",
    "- Save cleaned dataset to: `../data/processed/studies_clean.csv`\n",
    "\n",
    "### Output\n",
    "- âœ… `studies_clean.csv` â€” Cleaned and standardized dataset used for merges in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0d0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7baf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected fields from the `studies` table\n",
    "query = '''\n",
    "SELECT\n",
    "    nct_id,\n",
    "    start_month_year,\n",
    "    completion_month_year,\n",
    "    study_type,\n",
    "    enrollment,\n",
    "    overall_status,\n",
    "    phase,\n",
    "    number_of_arms,\n",
    "    has_dmc,\n",
    "    has_expanded_access,\n",
    "    is_fda_regulated_drug,\n",
    "    is_fda_regulated_device\n",
    "FROM ctgov.studies;\n",
    "'''\n",
    "df_studies = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2841193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for interventional studies and map outcomes to binary target\n",
    "df_studies = df_studies[df_studies['study_type'] == 'INTERVENTIONAL'].copy()\n",
    "\n",
    "final_outcomes = ['COMPLETED', 'TERMINATED', 'WITHDRAWN']\n",
    "df_studies = df_studies[df_studies['overall_status'].isin(final_outcomes)].copy()\n",
    "\n",
    "df_studies['overall_status'] = df_studies['overall_status'].map({\n",
    "    'COMPLETED': 1,\n",
    "    'TERMINATED': 0,\n",
    "    'WITHDRAWN': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25b42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for key categorical columns\n",
    "df_studies['is_fda_regulated_drug'] = df_studies['is_fda_regulated_drug'].fillna('unknown')\n",
    "df_studies['is_fda_regulated_device'] = df_studies['is_fda_regulated_device'].fillna('unknown')\n",
    "df_studies['has_expanded_access'] = df_studies['has_expanded_access'].fillna('unknown')\n",
    "df_studies['has_dmc'] = df_studies['has_dmc'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14237a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns and impute missing values\n",
    "df_studies['number_of_arms'] = pd.to_numeric(df_studies['number_of_arms'], errors = 'coerce')\n",
    "df_studies['number_of_arms'] = df_studies['number_of_arms'].fillna(df_studies['number_of_arms'].median())\n",
    "\n",
    "# Drop rows with missing dates\n",
    "df_studies = df_studies.dropna(subset = ['start_month_year', 'completion_month_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfbea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date columns and compute study duration\n",
    "from dateutil import parser\n",
    "def parse_date_safe(val):\n",
    "    try:\n",
    "        return parser.parse(val)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df_studies['start_month_year'] = df_studies['start_month_year'].apply(parse_date_safe)\n",
    "df_studies['completion_month_year'] = df_studies['completion_month_year'].apply(parse_date_safe)\n",
    "\n",
    "df_studies['duration_of_study'] = (\n",
    "    df_studies['completion_month_year'] - df_studies['start_month_year']\n",
    ").dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31346f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardise `phase` column\n",
    "df_studies['phase'] = df_studies['phase'].replace({'NA': 'NOT APPLICABLE', 'None': 'NOT APPLICABLE'})\n",
    "df_studies['phase'] = df_studies['phase'].fillna('NOT APPLICABLE')\n",
    "df_studies['phase'] = df_studies['phase'].str.lower()\n",
    "\n",
    "# Impute enrollment by median per phase\n",
    "df_studies['enrollment'] = pd.to_numeric(df_studies['enrollment'], errors = 'coerce')\n",
    "df_studies['enrollment'] = df_studies.groupby('phase')['enrollment'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Reassign mixed phases based on enrollment size\n",
    "size = 50\n",
    "df_studies.loc[(df_studies['phase'] == 'phase1/phase2') & (df_studies['enrollment'] <= size), 'phase'] = 'phase1'\n",
    "df_studies.loc[(df_studies['phase'] == 'phase1/phase2') & (df_studies['enrollment'] > size), 'phase'] = 'phase2'\n",
    "\n",
    "median_size = (\n",
    "    df_studies[df_studies['phase'] == 'phase2']['enrollment'].median() +\n",
    "    df_studies[df_studies['phase'] == 'phase3']['enrollment'].median()\n",
    ") / 2\n",
    "\n",
    "df_studies.loc[(df_studies['phase'] == 'phase2/phase3') & (df_studies['enrollment'] <= median_size), 'phase'] = 'phase2'\n",
    "df_studies.loc[(df_studies['phase'] == 'phase2/phase3') & (df_studies['enrollment'] > median_size), 'phase'] = 'phase3'\n",
    "\n",
    "df_studies['phase'] = df_studies['phase'].replace({'early_phase1': 'phase1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a28ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode flag like cols and one-hot encode `phase`\n",
    "binary_columns = ['has_dmc', 'is_fda_regulated_device', 'is_fda_regulated_drug', 'has_expanded_access']\n",
    "for col in binary_columns:\n",
    "    df_studies[col] = df_studies[col].map({True: 1, False: 0, 'unknown': -1})\n",
    "\n",
    "# Simplify and one-hot encode phase\n",
    "df_studies['phase'] = df_studies['phase'].str.replace('phase', '', regex=False)\n",
    "df_studies = pd.get_dummies(df_studies, columns = ['phase'], prefix = 'phase', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce22f57b-2a08-4631-8f2f-6557f98e2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns\n",
    "df_studies = df_studies.drop(columns = ['start_month_year', 'completion_month_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbeb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset to CSV\n",
    "df_studies.to_csv('../data/processed/studies_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bae140-4d67-47eb-8e67-e5b48bafe790",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary  \n",
    "This notebook successfully cleaned and standardized the `studies` table, preparing it for downstream feature integration and modeling.  \n",
    "\n",
    "Key transformations included:  \n",
    "- Parsing and computing **study duration** from start and completion dates.  \n",
    "- Cleaning and **reassigning mixed study phases** based on enrollment characteristics.  \n",
    "- Handling missing data and creating **binary target** and **flag variables**.  \n",
    "\n",
    "The resulting dataset â€” `studies_clean.csv` â€” forms the foundation for all subsequent merges and analyses.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“‚ **Next Notebook:** `2_df_baseline_features.ipynb` â†’ Adds demographic and baseline characteristics for each trial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
